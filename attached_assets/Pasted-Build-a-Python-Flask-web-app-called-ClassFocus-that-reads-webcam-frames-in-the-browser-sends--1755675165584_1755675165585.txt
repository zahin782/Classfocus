Build a Python + Flask web app called **ClassFocus** that reads webcam frames in the browser, sends a JPEG every 1 second to `/analyze`, and shows emotion + intensity + “Attentive / Not Attentive”. When the user clicks **Stop Camera**, calculate and display the percentage of time they were attentive during that session.

### Tech
- Python: `Flask`, `deepface`, `opencv-python-headless`, `numpy`
- Frontend: vanilla HTML/CSS/JS (no frameworks)
- Files: main.py, requirements.txt, static/index.html, static/style.css, static/app.js

### requirements.txt
flask==3.0.3
deepface==0.0.93
opencv-python-headless==4.10.0.84
numpy==1.26.4

---

### Backend rules (main.py)
1. `/` → serves index.html  
2. `/analyze` → POST JSON `{ image: "data:image/jpeg;base64,..." }`  
   - Decode image → numpy array  
   - Run DeepFace:
     ```python
     from deepface import DeepFace
     result = DeepFace.analyze(img, actions=['emotion'], enforce_detection=False)
     ```
   - Get dominant_emotion from result  
   - Map to **only 3 labels**:
     - if dominant is "happy" → emotion="happy"
     - if dominant is "sad" → emotion="sad"
     - if dominant is "neutral" → emotion="neutral"
     - else (angry, fear, disgust, surprise) → emotion="neutral"
   - **Intensity logic**:
     - For happy/sad:  
       - prob < 0.25 → "none"  
       - 0.25–0.49 → "low"  
       - 0.50–0.74 → "medium"  
       - ≥0.75 → "high"
     - For neutral: intensity = "none"
   - **Attentive rules**:
     - neutral → attentive = True  
     - happy/sad:
       - if intensity == "low" or "medium" → attentive = True  
       - if intensity == "high" → attentive = False
   - Respond JSON:
     ```json
     {
       "dominant": "happy", 
       "intensity": "medium", 
       "attentive": true
     }
     ```

---

### Frontend
- index.html → video preview, live status text, counters for frames  
- app.js:
  - Start Camera → use getUserMedia  
  - Every 1s → send frame to `/analyze`, update UI with dominant emotion, intensity, attentive status  
  - Track totalFrames + attentiveFrames  
  - Stop Camera → stop video, compute attentive% = (attentiveFrames/totalFrames)*100, display it

---

### UI rules
- Neutral → “Neutral — Attentive” (no intensity)  
- Happy low/med → “Happy (low/medium) — Attentive”  
- Happy high → “Happy (high) — Not Attentive”  
- Sad low/med → “Sad (low/medium) — Attentive”  
- Sad high → “Sad (high) — Not Attentive”  

---

### Edge cases
- No face → return dominant="neutral", attentive=True (so class time isn’t wasted)  
- Multiple faces → use DeepFace’s default dominant  
- Errors → don’t crash frontend, just keep video running  

---

### Run server
```python
if __name__ == "__main__":
    import os
    app.run(host="0.0.0.0", port=int(os.environ.get("PORT", 8080)))
